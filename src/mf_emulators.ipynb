{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03150cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import deepgp\n",
    "\n",
    "from GPy.models import GPRegression\n",
    "from emukit.test_functions import forrester_function\n",
    "from emukit.core.initial_designs import RandomDesign\n",
    "from emukit.model_wrappers import GPyModelWrapper\n",
    "from emukit.bayesian_optimization.acquisitions import ExpectedImprovement, NegativeLowerConfidenceBound, ProbabilityOfImprovement\n",
    "from emukit.core.optimization import GradientAcquisitionOptimizer\n",
    "from emukit.sensitivity.monte_carlo import MonteCarloSensitivity\n",
    "from gpflow.kernels import RBF, White, Linear\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f45c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                      | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day number: 10\n",
      "Day number: 20\n",
      "Day number: 30\n",
      "Day number: 40\n"
     ]
    }
   ],
   "source": [
    "from simulator import MainSimulator, TinySimulator\n",
    "from world import DebugInfo\n",
    "from pprint import pprint\n",
    "\n",
    "main_simulator = MainSimulator()\n",
    "\n",
    "mutation_rates = {\n",
    "    \"size\": 1,\n",
    "    \"speed\": 0,\n",
    "    \"vision\": 0,\n",
    "    \"aggression\": 0\n",
    "}\n",
    "\n",
    "days_log = []\n",
    "for i in tqdm(range(50)):\n",
    "    main_simulator = MainSimulator()\n",
    "    days_survived, log = main_simulator.run(mutation_rates, debug_info=DebugInfo(\n",
    "        period=10, should_display_day=True, should_display_grid=False, should_display_traits=False), max_days=1000)\n",
    "    days_log.append(days_survived)\n",
    "    print(days_survived)\n",
    "\n",
    "\n",
    "# for log_item in log[-3:-1]:\n",
    "#     print(log_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7617c8f5-3a74-4560-9151-e2a5e1bb3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(days_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTraitEmulator:\n",
    "    def __init__(self, X, Y, kernel, noise=1e-10):\n",
    "        self.model = GPyModelWrapper(GPRegression(X, Y, kernel, noise))\n",
    "    \n",
    "    def predict(self, X) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def set_data(self, X: np.ndarray, Y: np.ndarray) -> None:\n",
    "        self.model.set_data(X, Y)\n",
    "\n",
    "#TODO: Data Preprocessing\n",
    "X_size, Y_size = np.array([0,1,2,3]), np.array([1,3,7,2])\n",
    "# Assuming a general quadratic relationship between mutation rate and survival years\n",
    "size_kernel = GPy.kern.RatQuad(input_dim=1, power=1e4) * GPy.kern.Linear(1) * GPy.kern.Linear(-1)\n",
    "size_emulator = SingleTraitEmulator(X_size, Y_size, size_kernel)\n",
    "\n",
    "X_speed, Y_speed = np.array([0,1,2,3]), np.array([1,3,7,2])\n",
    "speed_kernel = GPy.kern.RatQuad(input_dim=1, power=1e4) * GPy.kern.Linear(1) * GPy.kern.Linear(-1)\n",
    "speed_emulator = SingleTraitEmulator(X_speed, Y_speed, speed_kernel)\n",
    "\n",
    "X_vision, Y_vision = np.array([0,1,2,3]), np.array([1,3,7,2])\n",
    "vision_kernel = GPy.kern.RatQuad(input_dim=1, power=1e4) * GPy.kern.Linear(1) * GPy.kern.Linear(-1)\n",
    "vision_emulator = SingleTraitEmulator(X_vision, Y_vision, vision_kernel)\n",
    "\n",
    "X_aggression, Y_agression = np.array([0,1,2,3]), np.array([1,3,7,2])\n",
    "aggression_kernel = GPy.kern.RatQuad(input_dim=1, power=1e4) * GPy.kern.Linear(1) * GPy.kern.Linear(-1)\n",
    "aggression_emulator = SingleTraitEmulator(X_aggression, Y_agression, aggression_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP using deepgp library\n",
    "\n",
    "num_layers = 1\n",
    "kern1 = GPy.kern.RBF(Q,ARD=True) + GPy.kern.Bias(num_layers)\n",
    "kern2 = GPy.kern.RBF(X_tr.shape[1],ARD=False) + GPy.kern.Bias(X_tr.shape[1])\n",
    "num_inducing = 40 # Number of inducing points to use for sparsification\n",
    "back_constraint = False # Whether to use back-constraint for variational posterior\n",
    "# encoder_dims=[[300],[150]] # Dimensions of the MLP back-constraint if set to true\n",
    "\n",
    "mf_model = deepgp.DeepGP([Y_combined.shape[1], num_layeres, X_combined.shape[1]], Y_combined, X_combined, kernels=[kern1, kern2], num_inducing=num_inducing, back_constraint=back_constraint)\n",
    "\n",
    "for i in range(len(mf_model.layers)):\n",
    "    output_var = m.layers[i].Y.var() if i==0 else m.layers[i].Y.mean.var()\n",
    "    m.layers[i].Gaussian_noise.variance = output_var*0.01\n",
    "    m.layers[i].Gaussian_noise.variance.fix()\n",
    "\n",
    "m.optimize(max_iters=800, messages=True)\n",
    "for i in range(len(m.layers)):\n",
    "    m.layers[i].Gaussian_noise.variance.unfix()\n",
    "\n",
    "m.optimize(max_iters=1500, messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f114c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP using emukit and gpflow\n",
    "\n",
    "def make_dgpMF_model(X=X_combined, Y=Y_combined):\n",
    "\n",
    "    Din = X[0].shape[1]\n",
    "    Dout = Y[0].shape[1]\n",
    "\n",
    "    kernels = [RBF(Din, active_dims=list(range(Din)), variance=1., lengthscales=10., ARD=True)]\n",
    "    for l in range(1,len(X)):\n",
    "        D = Din + Dout\n",
    "        D_range = list(range(D))\n",
    "        \n",
    "        k_corr_2 = RBF(Din, active_dims=D_range[:Din], lengthscales=0.1,  variance=1.5, ARD=True)\n",
    "        k_corr = k_corr_2\n",
    "        \n",
    "        k_prev = RBF(Dout, active_dims=D_range[Din:], variance = 1., lengthscales=0.1, ARD=True)\n",
    "        k_in = RBF(Din, active_dims=D_range[:Din], variance=0.1, lengthscales=1., ARD=True)\n",
    "        \n",
    "        k_bias = Linear(Dout, active_dims=D_range[Din:], variance = 1e-6)\n",
    "        k_in.variance = 1e-6\n",
    "        \n",
    "        k_l = k_corr*(k_prev + k_bias) + k_in\n",
    "        kernels.append(k_l)\n",
    "\n",
    "    for i, kernel in enumerate(kernels[:-1]):\n",
    "        kernels[i] += White(1, variance=0.)\n",
    "            \n",
    "    num_data = 0\n",
    "    for i in range(len(X)):\n",
    "        num_data += X[i].shape[0]\n",
    "        \n",
    "    layers = init_layers_mf(Y, X, kernels, num_outputs=1)\n",
    "        \n",
    "    model = DGP_Base(X, Y, Gaussian(), layers, num_samples=10, minibatch_size=1000)\n",
    "\n",
    "    return model\n",
    "\n",
    "def run(model, lr, iterations, callback=None):\n",
    "    adam = AdamOptimizer(lr).make_optimize_action(model)\n",
    "    actions = [adam] if callback is None else [adam, callback]\n",
    "    loop = Loop(actions, stop=iterations)()\n",
    "    model.anchor(model.enquire_session())\n",
    "    \n",
    "make_dgpMF_model([X_speed, X_combined], [Y_speed, Y_combined], [X_speed, X_combined])\n",
    "dgp_model.layers[0].feature.Z.trainable = False\n",
    "dgp_model.layers[1].feature.Z.trainable = False\n",
    "dgp_model.layers[0].q_sqrt.trainable = False\n",
    "dgp_model.likelihood.likelihood.variance.trainable = False\n",
    "dgp_model.run(0.01, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesOpt for low fidelity emulators\n",
    "\n",
    "_, space = forrester_function()\n",
    "iterations = 10\n",
    "\n",
    "ei_acquisition = ExpectedImprovement(speed_model)\n",
    "pi_acquisition = ProbabilityOfImprovement(speed_model)\n",
    "ucb_acquisition = NegativeLowerConfidenceBound(speed_model)\n",
    "\n",
    "for _ in range(iterations):\n",
    "    optimizer = GradientAcquisitionOptimizer(space)\n",
    "    x_new, _ = optimizer.optimize(ei_acquisition)\n",
    "    mutation_rate = {\"speed\":x_new, \"size\":0, \"vision\":0, \"aggression\":0,}\n",
    "    y_new = Simulator(mutation_rate)\n",
    "    X = np.append(X, x_new)\n",
    "    Y = np.append(Y, y_new)\n",
    "    speed_model.set_data(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e77f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity Analysis\n",
    "senstivity = MonteCarloSensitivity(model = speed_model, input_domain = space)\n",
    "main_effects, total_effects, _ = senstivity.compute_effects(num_monte_carlo_points = 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
